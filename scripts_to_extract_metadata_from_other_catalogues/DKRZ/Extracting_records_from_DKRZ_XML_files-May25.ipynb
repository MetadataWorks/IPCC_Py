{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:18:32.286015Z",
     "start_time": "2025-05-27T15:18:32.282498Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from nltk import tokenize\n",
    "import re\n",
    "import json\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:18:34.919513Z",
     "start_time": "2025-05-27T15:18:34.917162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folder where the xml files are located\n",
    "FILE_DIR = \"Input2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:18:37.606634Z",
     "start_time": "2025-05-27T15:18:37.603236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Reads in the filenames, and prints out how many start with \"oai\"\n",
    "\n",
    "filename_list = []\n",
    "for filename in os.listdir(FILE_DIR):\n",
    "    if filename.startswith('oai'):\n",
    "        filename_list.append(filename)\n",
    "print(len(filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:18:42.993589Z",
     "start_time": "2025-05-27T15:18:42.990700Z"
    }
   },
   "outputs": [],
   "source": [
    "# DKRZ use a number of tags for references.  These variables store the relevant tags against the agreed variable \n",
    "# in the IPCC DDC schema v2\n",
    "\n",
    "references_rel_types = ['IsDocumentedBy', 'Cites', 'IsDescribedBy', 'References']\n",
    "referencedby_rel_types = ['Documents', 'IsCitedBy', 'Describes', 'IsReferencedBy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML IMPORT AND MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:32:31.023811Z",
     "start_time": "2025-05-27T15:32:01.750381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dates found in the string.\n",
      "No dates found in the string.\n",
      "No dates found in the string.\n",
      "No dates found in the string.\n",
      "No dates found in the string.\n",
      "No dates found in the string.\n",
      "No dates found in the string.\n"
     ]
    }
   ],
   "source": [
    "# This script reads in the files and creates a list of python dictionaries, each one containing the mapped \n",
    "# metadata from each XML file\n",
    "\n",
    "import_list = []\n",
    "for xml_file in filename_list:\n",
    "    import_dict = {}\n",
    "    etree = ET.parse(os.path.join(FILE_DIR,xml_file))\n",
    "    root = etree.getroot()\n",
    "    \n",
    "    #### SUMMARY\n",
    "    \n",
    "    # Title\n",
    "    for titles in root.findall('{https://datacite.org/schema/kernel-4}titles'):\n",
    "        import_dict['Title'] = titles.find('{https://datacite.org/schema/kernel-4}title').text\n",
    "    \n",
    "    #Keywords\n",
    "    keyword_list = []\n",
    "    for keywords in root.findall('{http://datacite.org/schema/kernel-4}subjects'):\n",
    "        for keyword in keywords.findall('{http://datacite.org/schema/kernel-4}subject'):\n",
    "            keyword_list.append(keyword.text)\n",
    "    import_dict['Keywords'] = keyword_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    # DOI name, or alternative indentifiers\n",
    "    \n",
    "    '''\n",
    "    For DOIs, DKRZ provided the following detail on how to create resolvable URLS from the DOIs:\n",
    "    \n",
    "    We have persistent urls pointing to the landing page, which provide information about and access to the data. Unfortunately, we haven't these urls in the provided metadata and there are two construction rules based on the 'doi name'.\n",
    "    \n",
    "    special case for doi names with 'CMIP5.' \n",
    "    or which are like '10.1594/WDCC/CMIP5.': http://cera-www.dkrz.de/WDCC/CMIP5/Compact.jsp?acronym= \n",
    "    e.g. 10.1594/WDCC/CMIP5.MXELr4: http://cera-www.dkrz.de/WDCC/CMIP5/Compact.jsp?acronym=MXELr4\n",
    "    \n",
    "    all other cases, currently with 'doi names' like '10.1594/WDCC/ or '10.26050/WDCC/': \n",
    "    http://cera-www.dkrz.de/WDCC/ui/Compact.jsp?acronym= \n",
    "    e.g. '10.1594/WDCC/ETHr8': http://cera-www.dkrz.de/WDCC/ui/Compact.jsp?acronym=10.1594/WDCC/ETHr8\n",
    "    \n",
    "    Alternatively, we could use DOI resolver+DOI name: https://doi.org/\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for identifier in root.findall('{http://datacite.org/schema/kernel-4}identifier'):\n",
    "        id_type = identifier.get('identifierType')\n",
    "        if id_type == \"DOI\":\n",
    "            import_dict['DOI Name'] = identifier.text\n",
    "            import_dict['Alternate Identifier'] = ''\n",
    "            if identifier.text.startswith('10.1594/WDCC/CMIP5.'):\n",
    "                acronym = identifier.text.split('10.1594/WDCC/CMIP5.', 1)[1]\n",
    "                import_dict['Access URL'] = 'http://cera-www.dkrz.de/WDCC/CMIP5/Compact.jsp?acronym={}'.format(acronym)\n",
    "            else:\n",
    "                acronym = identifier.text.split('/WDCC/', 1)[1]\n",
    "                import_dict['Access URL'] = 'http://cera-www.dkrz.de/WDCC/ui/Compact.jsp?acronym={}'.format(acronym)\n",
    "        else:\n",
    "            import_dict['DOI Name'] = ''\n",
    "            import_dict['Alternate Identifier'] = identifier.text\n",
    "            import_dict['Access URL'] = identifier.text\n",
    "            \n",
    "    # Publication date\n",
    "    for dates in root.findall('{http://datacite.org/schema/kernel-4}dates'):\n",
    "        for date in dates.findall('{http://datacite.org/schema/kernel-4}date'):\n",
    "            date_type = date.get('dateType')\n",
    "            if date_type == \"Created\": import_dict['Publication Date'] = date.text\n",
    "            if date_type == \"Coverage\":  \n",
    "                match = re.search(r'>(\\d{4}-\\d{2}-\\d{2})/(\\d{4}-\\d{2}-\\d{2})<', date.text)\n",
    "                if match:\n",
    "                    coverage_start = match.group(1)\n",
    "                    coverage_end = match.group(2)\n",
    "                \n",
    "                    import_dict['Start Date'] = coverage_start\n",
    "                    import_dict['End Date'] = coverage_end\n",
    "                else:\n",
    "                    print(\"No dates found in the string.\")\n",
    "    #Publication year\n",
    "    for year in root.findall('{https://datacite.org/schema/kernel-4}publicationYear'):\n",
    "        import_dict['Publication Year'] = year.text\n",
    "        \n",
    "    \n",
    "    #### PUBLISHER \n",
    "    for publisher in root.findall('{https://datacite.org/schema/kernel-4}publisher'):\n",
    "        import_dict['Pub_Name'] = publisher.text\n",
    "        \n",
    "    #### DOCUMENTATION\n",
    "    \n",
    "    for descs in root.findall('{https://datacite.org/schema/kernel-4}descriptions'):\n",
    "        for desc in descs.findall('{https://datacite.org/schema/kernel-4}description'):\n",
    "            if desc.get('descriptionType') == \"Abstract\":\n",
    "                desc_text = desc.text\n",
    "                for summary in desc.iter():\n",
    "                    desc_text += summary.tail\n",
    "                    text = summary.tail\n",
    "                    if text.split(':')[0] == \"Summary\":\n",
    "                        # Using the first sentense of the summary section for the Abstract\n",
    "                        abstract_text = tokenize.sent_tokenize(text.split(':', 1)[1])[0]\n",
    "                        if len(abstract_text) > 180:\n",
    "                            abstract_text = abstract_text.split(')')[0]\n",
    "                        import_dict['Abstract'] = abstract_text\n",
    "                        \n",
    "                import_dict['Description'] = desc_text \n",
    "    \n",
    "    #### Coverage\n",
    "    for geo_locs in root.findall('{https://datacite.org/schema/kernel-4}geoLocations'):\n",
    "        for geo_loc in geo_locs.findall('{https://datacite.org/schema/kernel-4}geoLocation'):\n",
    "            for geo_loc_place in geo_loc.findall('{https://datacite.org/schema/kernel-4}geoLocationPlace'):\n",
    "                import_dict['Spatial Coverage'] = geo_loc_place.text\n",
    "            for geo_loc_bbox in geo_loc.findall('{https://datacite.org/schema/kernel-4}geoLocationBox'):\n",
    "                for west_long in geo_loc_bbox.findall('{https://datacite.org/schema/kernel-4}westBoundLongitude'):\n",
    "                    import_dict['Upper Right Longitude'] = west_long.text\n",
    "                for east_long in geo_loc_bbox.findall('{https://datacite.org/schema/kernel-4}eastBoundLongitude'):\n",
    "                    import_dict['Lower Left Longitude'] = east_long.text\n",
    "                for south_lat in geo_loc_bbox.findall('{https://datacite.org/schema/kernel-4}southBoundLatitude'):\n",
    "                    import_dict['Lower Left Latitude'] = south_lat.text\n",
    "                for north_lat in geo_loc_bbox.findall('{https://datacite.org/schema/kernel-4}northBoundLatitude'):\n",
    "                    import_dict['Upper Right Latitude'] = north_lat.text\n",
    "            \n",
    "    \n",
    "    #### USAGE\n",
    "    \n",
    "    # License\n",
    "    for rights in root.findall('{https://datacite.org/schema/kernel-4}rightsList'):\n",
    "        for right in rights.findall('{https://datacite.org/schema/kernel-4}rights'):\n",
    "            import_dict['License'] = right.text\n",
    "    \n",
    "    # Resource Creator\n",
    "    name_list = []\n",
    "    for creators in root.findall('{https://datacite.org/schema/kernel-4}creators'):\n",
    "        for creator in creators.findall('{https://datacite.org/schema/kernel-4}creator'):\n",
    "            for creator_name in creator.findall('{https://datacite.org/schema/kernel-4}creatorName'):\n",
    "                name_list.append(creator_name.text)\n",
    "    import_dict['Resource Creator'] = name_list\n",
    "    \n",
    "    #### Access\n",
    "    \n",
    "    # Access URL - see above section DOI name, or alternative indentifiers\n",
    "    \n",
    "    # language\n",
    "    for language in root.findall('{https://datacite.org/schema/kernel-4}language'):\n",
    "        import_dict['Language'] = language.text\n",
    "        \n",
    "    # format\n",
    "    format_list = []\n",
    "    for data_formats in root.findall('{https://datacite.org/schema/kernel-4}formats'):\n",
    "        for data_format in data_formats.findall('{https://datacite.org/schema/kernel-4}format'):\n",
    "            format_list.append(data_format.text)\n",
    "    import_dict['Format'] = format_list\n",
    "    \n",
    "    # references\n",
    "    for reference in root.findall('{https://datacite.org/schema/kernel-4}relatedIdentifiers'):\n",
    "        reference_list = []\n",
    "        referenced_by_list = []\n",
    "        qualified_relation_list = []\n",
    "        for ri in reference.findall('{https://datacite.org/schema/kernel-4}relatedIdentifier'):\n",
    "            rel_type = ri.attrib['relationType']\n",
    "            if rel_type in references_rel_types:\n",
    "                reference_list.append(\"https://doi.org/\" + ri.text)\n",
    "            elif rel_type in referencedby_rel_types:\n",
    "                referenced_by_list.append(\"https://doi.org/\" + ri.text)\n",
    "            else:\n",
    "                qualified_relation_list.append(\"https://doi.org/\" + ri.text)\n",
    "        import_dict['References'] = reference_list\n",
    "        import_dict['Is Referenced By'] = referenced_by_list\n",
    "        import_dict['Qualified Relation'] = qualified_relation_list\n",
    "    \n",
    "    #For fields with no match:\n",
    "    import_dict['License'] = ''\n",
    "    import_dict['Access Service']=''\n",
    "    import_dict['Purpose'] = ''\n",
    "    import_dict['Pub_Contact Point'] = 'data@dkrz.de'\n",
    "    import_dict['Associated Media'] = ''\n",
    "    import_dict['Is Part Of'] = ''\n",
    "    import_dict['Tools'] = ''\n",
    "    import_dict['Temporal Resolution']= '' \n",
    "    # import_dict['Start Date'] = ''\n",
    "    import_dict['Source'] = ''\n",
    "    import_dict['Spatial Resolution'] = ''\n",
    "    # import_dict['End Date'] = ''\n",
    "    import_dict['Investigations'] = '' \n",
    "    import_dict['Contact Point'] = 'data@dkrz.de'\n",
    "    import_dict['Pub_Identifier'] = 'https://ror.org/03ztgj037'\n",
    "    import_dict['Pub_Description'] = '' \n",
    "    import_dict['Pub_Logo'] = ''\n",
    "    import_dict['Spatial Aggregation'] = '' \n",
    "    import_dict['Jurisdiction'] = ''\n",
    "\n",
    "    import_list.append(import_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:36:29.301281Z",
     "start_time": "2025-05-27T15:36:29.285275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contact Point</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>DOI Name</th>\n",
       "      <th>Alternate Identifier</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Pub_Identifier</th>\n",
       "      <th>Pub_Logo</th>\n",
       "      <th>Pub_Description</th>\n",
       "      <th>Pub_Contact Point</th>\n",
       "      <th>Associated Media</th>\n",
       "      <th>...</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Source</th>\n",
       "      <th>License</th>\n",
       "      <th>Resource Creator</th>\n",
       "      <th>Investigations</th>\n",
       "      <th>Access URL</th>\n",
       "      <th>Access Service</th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Format</th>\n",
       "      <th>Tools</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/6262c7a278e9aa38167b3a26f6967e043d9102f4</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/6262c7a278e9aa38167b3a26f6967e043d9102f4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/f5f2eb708ebc76156ed21b85178240f5acecd8d3</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/f5f2eb708ebc76156ed21b85178240f5acecd8d3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, DKRZ, ECHAM3, ECHAM3-LSG, IPCC, IPCC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/6e71dbeb8ba8e39735e51066f3e6129ff3ec9611</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/6e71dbeb8ba8e39735e51066f3e6129ff3ec9611</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, DKRZ, ECHAM3, ECHAM3-LSG, IPCC, IPCC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/b6d91a7d70c3d58615971f7df31a9c57176f2c93</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/b6d91a7d70c3d58615971f7df31a9c57176f2c93</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/a3d64c373a232e98abed085f98ca546799922cd1</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/a3d64c373a232e98abed085f98ca546799922cd1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/171f69d5d1ca9c3095f32bb4e4a085770a724a7c</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/171f69d5d1ca9c3095f32bb4e4a085770a724a7c</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td>[Climate, DKRZ, ECHAM3, ECHAM3-LSG, IPCC, IPCC...</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/020b5547143dd754f0b54e51d9fd92f181d07fa9</td>\n",
       "      <td>2001-11-26</td>\n",
       "      <td>https://ror.org/03ztgj037</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data@dkrz.de</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>21.14106/020b5547143dd754f0b54e51d9fd92f181d07fa9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Contact Point                                           Keywords DOI Name  \\\n",
       "0  data@dkrz.de  [Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...            \n",
       "1  data@dkrz.de  [Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...            \n",
       "2  data@dkrz.de  [Climate, DKRZ, ECHAM3, ECHAM3-LSG, IPCC, IPCC...            \n",
       "3  data@dkrz.de  [Climate, DKRZ, ECHAM3, ECHAM3-LSG, IPCC, IPCC...            \n",
       "4  data@dkrz.de  [Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...            \n",
       "5  data@dkrz.de  [Climate, ECHAM4, ECHAM4-OPYC3, IPCC, IPCC-DDC...            \n",
       "6  data@dkrz.de  [Climate, DKRZ, ECHAM3, ECHAM3-LSG, IPCC, IPCC...            \n",
       "\n",
       "                                Alternate Identifier Publication Date  \\\n",
       "0  21.14106/6262c7a278e9aa38167b3a26f6967e043d9102f4       2001-11-26   \n",
       "1  21.14106/f5f2eb708ebc76156ed21b85178240f5acecd8d3       2001-11-26   \n",
       "2  21.14106/6e71dbeb8ba8e39735e51066f3e6129ff3ec9611       2001-11-26   \n",
       "3  21.14106/b6d91a7d70c3d58615971f7df31a9c57176f2c93       2001-11-26   \n",
       "4  21.14106/a3d64c373a232e98abed085f98ca546799922cd1       2001-11-26   \n",
       "5  21.14106/171f69d5d1ca9c3095f32bb4e4a085770a724a7c       2001-11-26   \n",
       "6  21.14106/020b5547143dd754f0b54e51d9fd92f181d07fa9       2001-11-26   \n",
       "\n",
       "              Pub_Identifier Pub_Logo Pub_Description Pub_Contact Point  \\\n",
       "0  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "1  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "2  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "3  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "4  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "5  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "6  https://ror.org/03ztgj037                               data@dkrz.de   \n",
       "\n",
       "  Associated Media  ... Purpose Source License Resource Creator  \\\n",
       "0                   ...                                      []   \n",
       "1                   ...                                      []   \n",
       "2                   ...                                      []   \n",
       "3                   ...                                      []   \n",
       "4                   ...                                      []   \n",
       "5                   ...                                      []   \n",
       "6                   ...                                      []   \n",
       "\n",
       "  Investigations                                         Access URL  \\\n",
       "0                 21.14106/6262c7a278e9aa38167b3a26f6967e043d9102f4   \n",
       "1                 21.14106/f5f2eb708ebc76156ed21b85178240f5acecd8d3   \n",
       "2                 21.14106/6e71dbeb8ba8e39735e51066f3e6129ff3ec9611   \n",
       "3                 21.14106/b6d91a7d70c3d58615971f7df31a9c57176f2c93   \n",
       "4                 21.14106/a3d64c373a232e98abed085f98ca546799922cd1   \n",
       "5                 21.14106/171f69d5d1ca9c3095f32bb4e4a085770a724a7c   \n",
       "6                 21.14106/020b5547143dd754f0b54e51d9fd92f181d07fa9   \n",
       "\n",
       "  Access Service Jurisdiction Format Tools  \n",
       "0                                 []        \n",
       "1                                 []        \n",
       "2                                 []        \n",
       "3                                 []        \n",
       "4                                 []        \n",
       "5                                 []        \n",
       "6                                 []        \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this script creates a dataframe in the same order as the MDW Bulk Import sheet\n",
    "\n",
    "df = pd.DataFrame(import_list)\n",
    "# column_order = ['Title', 'Abstract', 'Contact Point', 'Keywords', 'DOI Name', 'Alternate Identifier',\n",
    "#                 'Publication Date', 'Pub_Identifier', 'Pub_Name', 'Pub_Logo', 'Pub_Description', 'Pub_Contact Point', \n",
    "#                 'Description', 'Associated Media', 'Is Part Of', 'Spatial Coverage', 'Spatial Aggregation',\n",
    "#                 'Spatial Resolution', 'Start Date', 'End Date', 'Temporal Resolution', \n",
    "#                 'Lower Left Latitude', 'Lower Left Longitude', 'Upper Right Latitude', 'Upper Right Longitude',\n",
    "#                 'Purpose', 'Source', 'License', 'Resource Creator', 'Investigations',\n",
    "#                 'Is Referenced By', 'References', 'Access URL', 'Access Service',\n",
    "#                 'Jurisdiction', 'Language', 'Format', 'Qualified Relation', 'Tools']\n",
    "column_order = ['Contact Point', 'Keywords', 'DOI Name', 'Alternate Identifier',\n",
    "                'Publication Date', 'Pub_Identifier', 'Pub_Logo', 'Pub_Description', 'Pub_Contact Point', \n",
    "                 'Associated Media', 'Is Part Of',  'Spatial Aggregation',\n",
    "                'Spatial Resolution',  'Temporal Resolution', \n",
    "                 'Purpose', 'Source', 'License', 'Resource Creator', 'Investigations',\n",
    "                 'Access URL', 'Access Service',\n",
    "                'Jurisdiction',  'Format',  'Tools']\n",
    "df = df[column_order]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Clean up\n",
    "\n",
    "This section of the code converts python lists to JSON.\n",
    "\n",
    "It replaces empty lists with NaN.  Note: as per the Readme, before the excel spreadsheet can be imported into the MDX, you will need to Find all \"NaN\" and replace with a blank cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:36:41.353837Z",
     "start_time": "2025-05-27T15:36:41.350040Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_clean_column(a_pandas_series):\n",
    "    \n",
    "    # remove blanks\n",
    "    a_pandas_series = a_pandas_series.apply(lambda x: np.nan if len(x) == 0 else x)\n",
    "    \n",
    "    #replace single quotes with double quotes\n",
    "    a_pandas_series = a_pandas_series.apply(lambda x: json.dumps(x))\n",
    "    \n",
    "    return a_pandas_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:38:18.489152Z",
     "start_time": "2025-05-27T15:38:18.487231Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns_with_lists = ['Keywords', 'Resource Creator',  'Is Referenced By', 'References', \n",
    "#                       'Format', 'Qualified Relation']\n",
    "columns_with_lists = ['Keywords', 'Resource Creator',  'Format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:38:20.006733Z",
     "start_time": "2025-05-27T15:38:20.003156Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in columns_with_lists:\n",
    "    df[col] = json_clean_column(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:38:22.992975Z",
     "start_time": "2025-05-27T15:38:22.989607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-27\n"
     ]
    }
   ],
   "source": [
    "date = datetime.date(datetime.now())\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:38:25.951508Z",
     "start_time": "2025-05-27T15:38:25.948900Z"
    }
   },
   "outputs": [],
   "source": [
    "# This section of the code divides the records into seperate files containing no more than \n",
    "# n records per file for easy uploading\n",
    "\n",
    "n = 100  #chunk row size\n",
    "list_df = [df[i:i+n] for i in range(0,df.shape[0],n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:41:28.611438Z",
     "start_time": "2025-05-27T15:41:28.598451Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "file_number = 1\n",
    "for l_df in list_df:\n",
    "    with pd.ExcelWriter('Output2025/DKRZ_metadata_v1_{}_fileno_{}.xlsx'.format(date, file_number)) as writer:  \n",
    "        l_df.to_excel(writer, sheet_name='DKRZ_Datasets', index=False)\n",
    "    file_number +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:08:09.944508Z",
     "start_time": "2025-05-27T15:01:41.095384Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T15:08:09.944533Z",
     "start_time": "2025-05-27T15:01:41.536560Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
